{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull amygdala-seeded gPPI estimates with all regions in the Harvard-Oxford Atlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine here which roi masks to pull betas for, then flatten them\n",
    "\n",
    "This should be all masks in the Harvard-Oxford cortical and subcortical atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskPaths = glob.glob('../Parcellations/harvardOx/*.nii.gz')\n",
    "\n",
    "masks = ['none'] * len(maskPaths)\n",
    "for counter, maskPath in enumerate(maskPaths):\n",
    "    masks[counter] = image.load_img(maskPath)\n",
    "    masks[counter] = masks[counter].get_fdata()\n",
    "    masks[counter] = masks[counter].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to get gPPI estimates for any given ROI, run, ppi directory, contrast #, and image type (beta vs. tstat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPpiRoi(subject, roiMask, runType, ppiDir, copeNum, imageType):\n",
    "\n",
    "    # Pull for the emotional face and neutral face cope for each run\n",
    "    statImg = image.load_img('/danl/SB/Investigators/PaulCompileTGNG/data/%s/model/%s/24motion.feat/%s/reg_standard/stats/%s%s.nii.gz'%(subject, runType, ppiDir, imageType, copeNum))\n",
    "    statImg = statImg.get_fdata()\n",
    "    statImg = statImg.flatten()\n",
    "    \n",
    "    # Mask the cope images and filter based on mask == 1, then take means      \n",
    "    maskedStatImg= statImg[roiMask == 1]\n",
    "    meanStatImg = np.mean(maskedStatImg)\n",
    "    \n",
    "    # return value\n",
    "    return(meanStatImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull HO amyg connectivity with all regions, with deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame of all runs in feat\n",
    "subFrame = pd.read_csv('../QA/allEmotionsFeatComplete.csv')\n",
    "ppiDir = 'gppi_deconvolution_seed_harvardoxfordsubcortical_bilateralamyg.feat'\n",
    "\n",
    "subFrame = subFrame[subFrame['runType'] == 'fear'] \n",
    "for index, row in subFrame.iterrows():\n",
    "    for counter, roiMask in enumerate(masks):\n",
    "        maskPath = maskPaths[counter]\n",
    "        #print(maskPath)\n",
    "        maskPathSplit = maskPath.split('/')\n",
    "        roiName = maskPathSplit[3][:-7]\n",
    "        #print(roiName)\n",
    "        if(os.path.isfile('/danl/SB/Investigators/PaulCompileTGNG/data/%s/model/%s/24motion.feat/%s/reg_standard/stats/cope1.nii.gz'%(row['name'], row['runType'], ppiDir))):\n",
    "            subFrame.loc[index, 'phys_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 8, 'tstat')\n",
    "            subFrame.loc[index, 'emotPpi_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 9, 'tstat')\n",
    "            subFrame.loc[index, 'neutralPpi_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 10, 'tstat')\n",
    "            subFrame.loc[index, 'emotMinusNeutralPpi_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 11, 'tstat')\n",
    "\n",
    "# to csv\n",
    "subFrame.to_csv('gppi_deconvolution_seed_harvardoxfordsubcortical_bilateralamyg_ALL_HO_REGIONS.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull HO amyg connectivity with all regions, without deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame of all runs in feat\n",
    "subFrame = pd.read_csv('../QA/allEmotionsFeatComplete.csv')\n",
    "ppiDir = 'gppi_no_deconvolution_seed_harvardoxfordsubcortical_bilateralamyg.feat'\n",
    "\n",
    "subFrame = subFrame[subFrame['runType'] == 'fear'] \n",
    "for index, row in subFrame.iterrows():\n",
    "    for counter, roiMask in enumerate(masks):\n",
    "        maskPath = maskPaths[counter]\n",
    "        #print(maskPath)\n",
    "        maskPathSplit = maskPath.split('/')\n",
    "        roiName = maskPathSplit[3][:-7]\n",
    "        #print(roiName)\n",
    "        if(os.path.isfile('/danl/SB/Investigators/PaulCompileTGNG/data/%s/model/%s/24motion.feat/%s/reg_standard/stats/cope1.nii.gz'%(row['name'], row['runType'], ppiDir))):\n",
    "            subFrame.loc[index, 'phys_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 8, 'tstat')\n",
    "            subFrame.loc[index, 'emotPpi_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 9, 'tstat')\n",
    "            subFrame.loc[index, 'neutralPpi_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 10, 'tstat')\n",
    "            subFrame.loc[index, 'emotMinusNeutralPpi_%s_tstat'%(roiName)] = getPpiRoi(row['name'],roiMask,row['runType'], ppiDir, 11, 'tstat')\n",
    "\n",
    "# to csv\n",
    "subFrame.to_csv('gppi_no_deconvolution_seed_harvardoxfordsubcortical_bilateralamyg_ALL_HO_REGIONS.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
